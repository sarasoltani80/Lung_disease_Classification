{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls /kaggle/input/chest-xray-14-dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install torch torchvision transformers huggingface_hub","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob\nimport pandas as pd\nimport os\nfrom PIL import Image\nimport cv2\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom skimage import exposure \n\n# Load the CSV file\ndata = pd.read_csv('/kaggle/input/chest-xray-14-dataset/Data_Entry_2017.csv')\n# Print the number of rows and columns in the DataFrame\nprint(f\"Number of rows: {data.shape[0]}\")\nprint(f\"Number of columns: {data.shape[1]}\")\n\n\n# Load train and test image filenames\nwith open('/kaggle/input/chest-xray-14-dataset/train_val_list.txt') as f:\n    train_files = set(f.read().splitlines())\n    \nwith open('/kaggle/input/chest-xray-14-dataset/test_list.txt') as f:\n    test_files = set(f.read().splitlines())\n\n# Split the DataFrame into train and test sets based on filenames\ntrain_data = data[data['Image Index'].isin(train_files)]\ntest_data = data[data['Image Index'].isin(test_files)]\n\n# Process multi-labels for Finding Labels\ntrain_data.loc[:, 'Finding Labels'] = train_data['Finding Labels'].str.split('|')\ntest_data.loc[:, 'Finding Labels'] = test_data['Finding Labels'].str.split('|')\n\nmlb = MultiLabelBinarizer()\ntrain_labels = mlb.fit_transform(train_data['Finding Labels'])\ntest_labels = mlb.transform(test_data['Finding Labels'])\nclasses = mlb.classes_\n\n# Collect all image paths from nested directories\nall_image_paths = {os.path.basename(x): x for x in glob.glob('/kaggle/input/chest-xray-14-dataset/images_*/images/*.png', recursive=True)}\n\ndef lung_focused_preprocessing(image_path):\n    \"\"\"Applies lung-focused preprocessing to an X-ray image.\"\"\"\n    # Load the grayscale image\n    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n    \n    # Step 1: Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n    contrast_enhanced = clahe.apply(image)\n    \n    # Step 2: Suppress edges using smoothing (Gaussian Blur)\n    blurred = cv2.GaussianBlur(contrast_enhanced, (5, 5), 0)\n    \n    # Step 3: Enhance lung focus with intensity normalization\n    normalized = exposure.rescale_intensity(blurred, in_range=(50, 200), out_range=(0, 255)).astype(np.uint8)\n    #normalized = cv2.normalize(blurred, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n    \n    return normalized\n\nclass ChestXRayDataset(Dataset):\n    def __init__(self, df, labels, image_paths, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.labels = labels\n        self.image_paths = image_paths\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_name = self.df.loc[idx, 'Image Index']\n        img_path = self.image_paths.get(img_name)\n        \n        if img_path is None:\n            raise FileNotFoundError(f\"Image {img_name} not found in specified directories.\")\n        \n        # Apply lung-focused preprocessing\n        preprocessed_image = lung_focused_preprocessing(img_path)\n        \n        # Convert to PIL image for compatibility with PyTorch transforms\n        image = Image.fromarray(preprocessed_image).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n        \n        return image, label\n\n# Define transformations (after preprocessing)\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Ensure all images are 224x224\n    transforms.ToTensor(),\n])\n\nclass_counts = train_labels.sum(axis=0)\nprint(pd.DataFrame({'Class': classes, 'Count': class_counts}))\n\nlabel_counts = train_labels.sum(axis=0)\nprint(dict(zip(classes, label_counts)))\n\nno_labels = np.sum(np.sum(train_labels, axis=1) == 0)\nprint(f\"Samples with no labels: {no_labels}\")\n\n\n# Split the training data into 90% train and 10% validation\ntrain_df, val_df, train_labels_split, val_labels_split = train_test_split(\n    train_data, train_labels, test_size=0.1, random_state=42\n)\n\n# Initialize datasets and loaders\ntrain_dataset = ChestXRayDataset(train_df, train_labels_split, all_image_paths, transform)\nval_dataset = ChestXRayDataset(val_df, val_labels_split, all_image_paths, transform)\ntest_dataset = ChestXRayDataset(test_data, test_labels, all_image_paths, transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n\nprint(f\"Training set size: {len(train_dataset)}\")\nprint(f\"Validation set size: {len(val_dataset)}\")\nprint(f\"Test set size: {len(test_dataset)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nfrom timm import create_model\nfrom tqdm import tqdm\nimport torch.nn.functional as F\nimport os\nimport zipfile\nimport shutil\n\n# Define constants\nnum_epochs = 1\nlearning_rate = 0.001\nbatch_size = 32\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ncheckpoint_path = '/kaggle/working/model_trial_checkpoint.pth'  # Path to save the model checkpoint\nzip_checkpoint_path = '/kaggle/working/model_trial_checkpoint.zip'  # Path to save the zip file\n\n# Initialize model\ndef initialize_model(pretrained=False):\n    model = create_model('swinv2_cr_small_224', pretrained=pretrained)\n    \n    # Custom forward function to flatten features\n    def forward(self, x):\n        x = self.forward_features(x)\n        x = x.reshape(x.size(0), -1)  # Flatten to [batch_size, 50176] or compatible shape\n        return self.head(x)\n\n    model.forward = forward.__get__(model)  # Bind custom forward to the model instance\n    \n    # Replace the head to match the number of classes\n    model.head = nn.Linear(model.head.in_features * 7 * 7, len(classes))\n    \n    return model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # For multi-label classification\n\ndef save_checkpoint(model, optimizer, trial_num, path=checkpoint_path):\n    \"\"\"Save the model checkpoint and zip it.\"\"\"\n    # Save checkpoint\n    torch.save({\n        'trial': trial_num,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n    }, path)\n    print(f\"Checkpoint saved at trial {trial_num + 1}\")\n    \n    # Zip checkpoint\n    with zipfile.ZipFile(zip_checkpoint_path, 'w') as zipf:\n        zipf.write(path, os.path.basename(path))\n    print(f\"Checkpoint zipped at {zip_checkpoint_path}\")\n\ndef load_checkpoint(model, optimizer, path=checkpoint_path):\n    \"\"\"Load the model checkpoint if it exists.\"\"\"\n    if os.path.isfile(path):\n        checkpoint = torch.load(path)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        start_trial = checkpoint['trial'] + 1\n        print(f\"Resuming training from trial {start_trial}\")\n        return start_trial\n    else:\n        print(\"No checkpoint found. Starting trials from scratch.\")\n        return 0\n\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for images, labels in tqdm(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten to [batch_size, num_classes]\n\n            loss = criterion(outputs, labels.float())\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n\n# Function to evaluate the model\ndef evaluate_model(model, test_loader):\n    model.eval()\n    all_labels = []\n    all_outputs = []\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten outputs\n            all_labels.append(labels.numpy())\n            all_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n    \n    all_labels = np.vstack(all_labels)\n    all_outputs = np.vstack(all_outputs)\n    \n    return roc_auc_score(all_labels, all_outputs, average='macro')\n\n# Run independent trials for both training approaches\ndef run_trials(trials=10):\n    auc_scores_scratch = []\n    \n    for trial_num in range(trials):\n        # Training from scratch\n        model_scratch = initialize_model(pretrained=False)\n        optimizer_scratch = optim.Adam(model_scratch.parameters(), lr=learning_rate)\n        \n        # Load checkpoint if available\n        start_trial = load_checkpoint(model_scratch, optimizer_scratch, checkpoint_path)\n        if trial_num < start_trial:\n            continue  # Skip already completed trials\n        \n        train_model(model_scratch, train_loader, criterion, optimizer_scratch, num_epochs)\n        auc_scratch = evaluate_model(model_scratch, test_loader)\n        auc_scores_scratch.append(auc_scratch)\n        \n        # Save checkpoint after each trial\n        save_checkpoint(model_scratch, optimizer_scratch, trial_num, checkpoint_path)\n\n    return auc_scores_scratch\n\n# Execute the trials\nauc_scratch = run_trials()\nprint(\"AUC Scores (Training from Scratch):\", auc_scratch)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom internimage import internimage_t\nfrom sklearn.metrics import roc_auc_score\nfrom timm import create_model\nfrom tqdm import tqdm\nimport torch.nn.functional as F\nimport os\nimport zipfile\nimport shutil\n\n# Define constants\nnum_epochs = 1\nlearning_rate = 0.001\nbatch_size = 32\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ncheckpoint_path = '/kaggle/working/model_trial_checkpoint.pth'  # Path to save the model checkpoint\nzip_checkpoint_path = '/kaggle/working/model_trial_checkpoint.zip'  # Path to save the zip file\n\n# Initialize ConvNeXt model\ndef initialize_model(pretrained=False):\n    # Load ConvNeXt model\n    model = create_model('convnext_tiny', pretrained=pretrained)\n\n    # Custom forward function to flatten features\n    def forward(self, x):\n        x = self.forward_features(x)  # ConvNeXt uses forward_features\n        x = x.reshape(x.size(0), -1)  # Flatten to [batch_size, num_features]\n        return self.head(x)\n\n    model.forward = forward.__get__(model)  # Bind custom forward to the model instance\n\n    # Replace the head to match the number of classes\n    num_features = model.head.in_features  # Get input features of the head\n    model.head = nn.Linear(num_features, len(classes))  # Adjust for your classes\n\n    return model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # For multi-label classification\n\ndef save_checkpoint(model, optimizer, trial_num, path=checkpoint_path):\n    \"\"\"Save the model checkpoint and zip it.\"\"\"\n    # Save checkpoint\n    torch.save({\n        'trial': trial_num,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n    }, path)\n    print(f\"Checkpoint saved at trial {trial_num + 1}\")\n    \n    # Zip checkpoint\n    with zipfile.ZipFile(zip_checkpoint_path, 'w') as zipf:\n        zipf.write(path, os.path.basename(path))\n    print(f\"Checkpoint zipped at {zip_checkpoint_path}\")\n\ndef load_checkpoint(model, optimizer, path=checkpoint_path):\n    \"\"\"Load the model checkpoint if it exists.\"\"\"\n    if os.path.isfile(path):\n        checkpoint = torch.load(path)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        start_trial = checkpoint['trial'] + 1\n        print(f\"Resuming training from trial {start_trial}\")\n        return start_trial\n    else:\n        print(\"No checkpoint found. Starting trials from scratch.\")\n        return 0\n\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for images, labels in tqdm(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten to [batch_size, num_classes]\n\n            loss = criterion(outputs, labels.float())\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n\n# Function to evaluate the model\ndef evaluate_model(model, test_loader):\n    model.eval()\n    all_labels = []\n    all_outputs = []\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten outputs\n            all_labels.append(labels.numpy())\n            all_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n    \n    all_labels = np.vstack(all_labels)\n    all_outputs = np.vstack(all_outputs)\n    \n    return roc_auc_score(all_labels, all_outputs, average='macro')\n\n# Run independent trials for both training approaches\ndef run_trials(trials=10):\n    auc_scores_scratch = []\n    \n    for trial_num in range(trials):\n        # Training from scratch\n        model_scratch = initialize_model(pretrained=False)\n        optimizer_scratch = optim.Adam(model_scratch.parameters(), lr=learning_rate)\n        \n        # Load checkpoint if available\n        start_trial = load_checkpoint(model_scratch, optimizer_scratch, checkpoint_path)\n        if trial_num < start_trial:\n            continue  # Skip already completed trials\n        \n        train_model(model_scratch, train_loader, criterion, optimizer_scratch, num_epochs)\n        auc_scratch = evaluate_model(model_scratch, test_loader)\n        auc_scores_scratch.append(auc_scratch)\n        \n        # Save checkpoint after each trial\n        save_checkpoint(model_scratch, optimizer_scratch, trial_num, checkpoint_path)\n\n    return auc_scores_scratch\n\n# Execute the trials\nauc_scratch = run_trials()\nprint(\"AUC Scores (Training from Scratch):\", auc_scratch)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nfrom timm import create_model\nfrom tqdm import tqdm\nimport torch.nn.functional as F\nimport os\nimport zipfile\nimport shutil\n\n# Define constants\nnum_epochs = 1\nlearning_rate = 0.001\nbatch_size = 32\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ncheckpoint_path = '/kaggle/working/model_trial_checkpoint.pth'  # Path to save the model checkpoint\nzip_checkpoint_path = '/kaggle/working/model_trial_checkpoint.zip'  # Path to save the zip file\n\n# Initialize ConvNeXt model\ndef initialize_model(pretrained=False):\n    # Load ConvNeXt model\n    model = create_model('convnext_tiny', pretrained=pretrained)\n\n    # Custom forward function to flatten features\n    def forward(self, x):\n        x = self.forward_features(x)  # ConvNeXt uses forward_features\n        x = x.reshape(x.size(0), -1)  # Flatten to [batch_size, num_features]\n        return self.head(x)\n\n    model.forward = forward.__get__(model)  # Bind custom forward to the model instance\n\n    # Replace the head to match the number of classes\n    num_features = model.head.in_features  # Get input features of the head\n    print(num_features)\n    model.head = nn.Linear(37632, len(classes))  # Adjust for your classes\n\n    return model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # For multi-label classification\n\ndef save_checkpoint(model, optimizer, trial_num, path=checkpoint_path):\n    \"\"\"Save the model checkpoint and zip it.\"\"\"\n    # Save checkpoint\n    torch.save({\n        'trial': trial_num,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n    }, path)\n    print(f\"Checkpoint saved at trial {trial_num + 1}\")\n    \n    # Zip checkpoint\n    with zipfile.ZipFile(zip_checkpoint_path, 'w') as zipf:\n        zipf.write(path, os.path.basename(path))\n    print(f\"Checkpoint zipped at {zip_checkpoint_path}\")\n\ndef load_checkpoint(model, optimizer, path=checkpoint_path):\n    \"\"\"Load the model checkpoint if it exists.\"\"\"\n    if os.path.isfile(path):\n        checkpoint = torch.load(path)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        start_trial = checkpoint['trial'] + 1\n        print(f\"Resuming training from trial {start_trial}\")\n        return start_trial\n    else:\n        print(\"No checkpoint found. Starting trials from scratch.\")\n        return 0\n\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for images, labels in tqdm(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten to [batch_size, num_classes]\n\n            loss = criterion(outputs, labels.float())\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n\n# Function to evaluate the model\ndef evaluate_model(model, test_loader):\n    model.eval()\n    all_labels = []\n    all_outputs = []\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten outputs\n            all_labels.append(labels.numpy())\n            all_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n    \n    all_labels = np.vstack(all_labels)\n    all_outputs = np.vstack(all_outputs)\n    \n    return roc_auc_score(all_labels, all_outputs, average='macro')\n\n# Run independent trials for both training approaches\ndef run_trials(trials=10):\n    auc_scores_scratch = []\n    \n    for trial_num in range(trials):\n        # Training from scratch\n        model_scratch = initialize_model(pretrained=False)\n        optimizer_scratch = optim.Adam(model_scratch.parameters(), lr=learning_rate)\n        \n        # Load checkpoint if available\n        start_trial = load_checkpoint(model_scratch, optimizer_scratch, checkpoint_path)\n        if trial_num < start_trial:\n            continue  # Skip already completed trials\n        \n        train_model(model_scratch, train_loader, criterion, optimizer_scratch, num_epochs)\n        auc_scratch = evaluate_model(model_scratch, test_loader)\n        auc_scores_scratch.append(auc_scratch)\n        \n        # Save checkpoint after each trial\n        save_checkpoint(model_scratch, optimizer_scratch, trial_num, checkpoint_path)\n\n    return auc_scores_scratch\n\ndef train_model_with_validation(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n    \"\"\"Train the model and validate after each epoch.\"\"\"\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten to [batch_size, num_classes]\n\n            loss = criterion(outputs, labels.float())\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        # Print training loss\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n        \n        # Validate model\n        val_auc = evaluate_model(model, val_loader)\n        print(f\"Validation AUC after Epoch {epoch+1}: {val_auc:.4f}\")\n\ndef run_trials_with_validation(trials=10, param_grid=None):\n    \"\"\"Run trials with hyperparameter optimization and validation.\"\"\"\n    if param_grid is None:\n        # Define a grid of hyperparameters to try\n        param_grid = {\n            'learning_rate': [0.0005, 0.0001],\n            'batch_size': [16, 32, 64],\n            'optimizer': ['Adam', 'SGD', 'RMSprop'],\n        }\n    \n    best_auc = 0.0\n    best_params = {}\n    results = []\n\n    for learning_rate in param_grid['learning_rate']:\n        for batch_size in param_grid['batch_size']:\n            for optimizer_type in param_grid['optimizer']:\n                print(f\"\\nTesting configuration: LR={learning_rate}, Batch Size={batch_size}, Optimizer={optimizer_type}\")\n\n                # Initialize DataLoader with the given batch size\n                train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n                val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n                auc_scores = []  # AUC scores for this configuration\n\n                for trial_num in range(trials):\n                    # Initialize model\n                    model = initialize_model(pretrained=False)\n\n                    # Define optimizer\n                    if optimizer_type == 'Adam':\n                        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n                    elif optimizer_type == 'SGD':\n                        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n                    elif optimizer_type == 'RMSprop':\n                        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n                    \n                    # Load checkpoint if available\n                    start_trial = load_checkpoint(model, optimizer, checkpoint_path)\n                    if trial_num < start_trial:\n                        continue  # Skip already completed trials\n                    \n                    # Train model with validation\n                    train_model_with_validation(model, train_loader, val_loader, criterion, optimizer, num_epochs)\n\n                    # Evaluate on validation set\n                    val_auc = evaluate_model(model, val_loader)\n                    auc_scores.append(val_auc)\n                \n                # Average AUC for this configuration\n                avg_auc = np.mean(auc_scores)\n                print(f\"Configuration AUC: {avg_auc:.4f}\")\n\n                results.append({'learning_rate': learning_rate, 'batch_size': batch_size, \n                                'optimizer': optimizer_type, 'avg_auc': avg_auc})\n                \n                # Update the best configuration\n                if avg_auc > best_auc:\n                    best_auc = avg_auc\n                    best_params = {'learning_rate': learning_rate, \n                                   'batch_size': batch_size, \n                                   'optimizer': optimizer_type}\n\n    print(\"\\nBest Configuration:\", best_params)\n    print(\"Best AUC:\", best_auc)\n    return results, best_params\n\n# Execute the trials\nparam_grid = {\n    'learning_rate': [0.0005, 0.0001],\n    'batch_size': [16, 32, 64],\n    'optimizer': ['Adam', 'SGD', 'RMSprop'],\n}\n\nauc_results, best_hyperparams = run_trials_with_validation(trials=1, param_grid=param_grid)\nprint(\"AUC Results for All Configurations:\", auc_results)\nprint(\"Best Hyperparameters:\", best_hyperparams)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nfrom timm import create_model\nfrom tqdm import tqdm\nimport torch.nn.functional as F\nimport os\n\n# Define constants\nnum_epochs = 1\nlearning_rate = 0.001\nbatch_size = 32\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ncheckpoint_path = '/kaggle/working/model_trial_checkpoint.pth'  # Path to save the model checkpoint\n\n# Initialize model\ndef initialize_model(pretrained=False):\n    model = create_model('swin_base_patch4_window7_224', pretrained=pretrained)\n    \n    # Custom forward function to flatten features\n    def forward(self, x):\n        x = self.forward_features(x)\n        x = x.view(x.size(0), -1)  # Flatten to [batch_size, 50176] or compatible shape\n        return self.head(x)\n\n    model.forward = forward.__get__(model)  # Bind custom forward to the model instance\n    \n    # Replace the head to match the number of classes\n    model.head = nn.Linear(model.head.in_features * 7 * 7, len(classes))\n    \n    return model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # For multi-label classification\n\ndef save_checkpoint(model, optimizer, trial_num, path=checkpoint_path):\n    \"\"\"Save the model checkpoint.\"\"\"\n    torch.save({\n        'trial': trial_num,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n    }, path)\n    print(f\"Checkpoint saved at trial {trial_num + 1}\")\n\ndef load_checkpoint(model, optimizer, path=checkpoint_path):\n    \"\"\"Load the model checkpoint if it exists.\"\"\"\n    if os.path.isfile(path):\n        checkpoint = torch.load(path)\n        model.load_state_dict(checkpoint['model_state_dict'])\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n        start_trial = checkpoint['trial'] + 1\n        print(f\"Resuming training from trial {start_trial}\")\n        return start_trial\n    else:\n        print(\"No checkpoint found. Starting trials from scratch.\")\n        return 0\n\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for images, labels in tqdm(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten to [batch_size, num_classes]\n\n            loss = criterion(outputs, labels.float())\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n\n# Function to evaluate the model\ndef evaluate_model(model, test_loader):\n    model.eval()\n    all_labels = []\n    all_outputs = []\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten outputs\n            all_labels.append(labels.numpy())\n            all_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n    \n    all_labels = np.vstack(all_labels)\n    all_outputs = np.vstack(all_outputs)\n    \n    return roc_auc_score(all_labels, all_outputs, average='macro')\n\n# Run independent trials for both training approaches\ndef run_trials(trials=10):\n    auc_scores_scratch = []\n    \n    for trial_num in range(trials):\n        # Training from scratch\n        model_scratch = initialize_model(pretrained=False)\n        optimizer_scratch = optim.Adam(model_scratch.parameters(), lr=learning_rate)\n        \n        # Load checkpoint if available\n        start_trial = load_checkpoint(model_scratch, optimizer_scratch, checkpoint_path)\n        if trial_num < start_trial:\n            continue  # Skip already completed trials\n        \n        train_model(model_scratch, train_loader, criterion, optimizer_scratch, num_epochs)\n        auc_scratch = evaluate_model(model_scratch, test_loader)\n        auc_scores_scratch.append(auc_scratch)\n        \n        # Save checkpoint after each trial\n        save_checkpoint(model_scratch, optimizer_scratch, trial_num, checkpoint_path)\n\n    return auc_scores_scratch\n\n# Execute the trials\nauc_scratch = run_trials()\nprint(\"AUC Scores (Training from Scratch):\", auc_scratch)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install img2vec_pytorch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from img2vec_pytorch import Img2Vec\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom torchvision.transforms.functional import to_pil_image\nimport torch\n\n# Initialize Img2Vec\nimg2vec = Img2Vec(cuda=torch.cuda.is_available(), model='resnet18')\n\n# Function to extract features from dataset using Img2Vec\ndef extract_features_and_labels(data_loader):\n    features = []\n    labels = []\n\n    for images, label_batch in data_loader:\n        for i in range(images.size(0)):\n            pil_image = to_pil_image(images[i])\n            # Extract features for each image\n            img_vector = img2vec.get_vec(pil_image)\n            features.append(img_vector)\n            labels.append(label_batch[i].numpy())\n\n    return np.array(features), np.array(labels)\n\n# Extract features and labels for train and validation datasets\nprint(\"Extracting features from training data...\")\ntrain_features, train_labels = extract_features_and_labels(train_loader)\n\nprint(\"Extracting features from validation data...\")\nval_features, val_labels = extract_features_and_labels(test_loader)\n\n# If multi-label, convert one-hot encoded labels to class indices\ntrain_labels = np.argmax(train_labels, axis=1)\nval_labels = np.argmax(val_labels, axis=1)\n\n# Initialize and train the Random Forest classifier\nrf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\nprint(\"Training Random Forest classifier...\")\nrf_classifier.fit(train_features, train_labels)\n\n# Evaluate the model on validation data\nval_predictions = rf_classifier.predict(val_features)\n\n# Calculate and print accuracy and classification report\nval_accuracy = accuracy_score(val_labels, val_predictions)\nprint(\"Validation Accuracy:\", val_accuracy)\nprint(\"Classification Report:\")\nprint(classification_report(val_labels, val_predictions, target_names=classes))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = YOLO('yolov8n-cls.pt')\nmodel","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nfrom timm import create_model\nfrom tqdm import tqdm\nimport torch.nn.functional as F\nfrom transformers import AutoModel, AutoConfig\n#from torchsummary import summary\nimport types\nfrom ultralytics import YOLO\n\n\n# Define constants\nnum_epochs = 1\nlearning_rate = 0.0001\nbatch_size = 16\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Initialize model\ndef initialize_model(pretrained=True):\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = YOLO('yolov8n-cls.pt')\n    model.linear = nn.Linear(in_features=768, out_features=len(classes))\n    #model.new_head = nn.Linear(768, len(classes))\n\n# Update forward pass manually\n    def forward_with_new_head(self, x):\n        #print(f\"Shape before all: {x.shape}\")\n        x = self.model(x)  # Original forward\n        if isinstance(x, tuple):\n            x = x[0]\n        #print(f\"Shape before new_head: {x.shape}\")\n        #x = self.new_head(x)  # New layer\n        #print(f\"Shape after new_head: {x.shape}\")\n        return x\n\n# Bind the new forward function to the model\n    \n    model.forward = types.MethodType(forward_with_new_head, model)\n    \n    #print(model)\n    #summary(model, input_size=(3,224,224))\n    return model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # For multi-label classification\n\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for images, labels in tqdm(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            #print('images.shape is:', images.shape)\n            outputs = model(images)\n            if isinstance(outputs, tuple):  # Some models may return multiple outputs\n                outputs = outputs[0]  # Extract the logits\n            #print('outputs1.shape is:', outputs.shape)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten to [batch_size, num_classes]\n            #print('outputs.shape is:', outputs.shape)\n            loss = criterion(outputs, labels.float())\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n\n# Function to evaluate the model\ndef evaluate_model(model, test_loader):\n    model.eval()\n    all_labels = []\n    all_outputs = []\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten outputs\n            all_labels.append(labels.numpy())\n            all_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n    \n    all_labels = np.vstack(all_labels)\n    all_outputs = np.vstack(all_outputs)\n    \n    return roc_auc_score(all_labels, all_outputs, average='macro')\n\n# Run independent trials for both training approaches\ndef run_trials(trials=1):\n    auc_scores_scratch = []\n    \n    for trial_num in range(trials):\n        # Training from scratch\n        model_scratch = initialize_model(pretrained=True)\n        optimizer_scratch = optim.Adam(model_scratch.parameters(), lr=learning_rate)\n        \n        train_model(model_scratch, train_loader, criterion, optimizer_scratch, num_epochs)\n        auc_scratch = evaluate_model(model_scratch, test_loader)\n        print('auc_scratch is:', auc_scratch)\n        auc_scores_scratch.append(auc_scratch)\n\n    return auc_scores_scratch\n\n# Execute the trials\nauc_scratch = run_trials()\nprint(\"AUC Scores (Training from Scratch):\", auc_scratch)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**just fine tune fc**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nfrom timm import create_model\nfrom tqdm import tqdm\nimport torch.nn.functional as F\n\n# Define constants\nnum_epochs = 1\nlearning_rate = 0.0001\nbatch_size = 16\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Initialize model\ndef initialize_model(pretrained=True):\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model = create_model('convnext_tiny', pretrained=True)\n    model.head.fc = nn.Linear(in_features=768, out_features=len(classes))\n    model.to(device)\n\n    for name, param in model.named_parameters():\n        if \"fc\" not in name:\n            param.requires_grad_(False)\n            #print(param)\n\n    #summary(model, input_size=(3,224,224))\n\n    return model.to(device)\n\n\n# Loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # For multi-label classification\n\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for images, labels in tqdm(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten to [batch_size, num_classes]\n\n            loss = criterion(outputs, labels.float())\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n\n# Function to evaluate the model\ndef evaluate_model(model, test_loader):\n    model.eval()\n    all_labels = []\n    all_outputs = []\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten outputs\n            all_labels.append(labels.numpy())\n            all_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n    \n    all_labels = np.vstack(all_labels)\n    all_outputs = np.vstack(all_outputs)\n    \n    return roc_auc_score(all_labels, all_outputs, average='macro')\n\n# Run independent trials for both training approaches\ndef run_trials(trials=4):\n    auc_scores_scratch = []\n    \n    for trial_num in range(trials):\n        # Training from scratch\n        model_scratch = initialize_model(pretrained=True)\n        optimizer_scratch = optim.Adam(model_scratch.parameters(), lr=learning_rate)\n        \n        train_model(model_scratch, train_loader, criterion, optimizer_scratch, num_epochs)\n        auc_scratch = evaluate_model(model_scratch, test_loader)\n        print('auc_scratch is:', auc_scratch)\n        auc_scores_scratch.append(auc_scratch)\n\n    return auc_scores_scratch\n\n# Execute the trials\nauc_scratch = run_trials()\nprint(\"AUC Scores (Training from Scratch):\", auc_scratch)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**full fine tuning**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nfrom timm import create_model\nfrom tqdm import tqdm\nimport torch.nn.functional as F\n\n# Define constants\nnum_epochs = 1\nlearning_rate = 0.0001\nbatch_size = 16\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Initialize model\ndef initialize_model(pretrained=True):\n    model = create_model('convnext_tiny', pretrained=pretrained)\n    \n    # Custom forward function to flatten features\n    def forward(self, x):\n        x = self.forward_features(x)\n        x = x.reshape(x.size(0), -1)  # Flatten to [batch_size, 50176] or compatible shape\n        return self.head(x)\n\n    model.forward = forward.__get__(model)  # Bind custom forward to the model instance\n    \n    # Replace the head to match the number of classes\n    model.head = nn.Linear(model.head.in_features * 7 * 7, len(classes))\n    \n    return model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # For multi-label classification\n\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for images, labels in tqdm(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten to [batch_size, num_classes]\n\n            loss = criterion(outputs, labels.float())\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n\n# Function to evaluate the model\ndef evaluate_model(model, test_loader):\n    model.eval()\n    all_labels = []\n    all_outputs = []\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten outputs\n            all_labels.append(labels.numpy())\n            all_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n    \n    all_labels = np.vstack(all_labels)\n    all_outputs = np.vstack(all_outputs)\n    \n    return roc_auc_score(all_labels, all_outputs, average='macro')\n\n# Run independent trials for both training approaches\ndef run_trials(trials=10):\n    auc_scores_scratch = []\n    \n    for trial_num in range(trials):\n        # Training from scratch\n        model_scratch = initialize_model(pretrained=True)\n        optimizer_scratch = optim.Adam(model_scratch.parameters(), lr=learning_rate)\n        \n        train_model(model_scratch, train_loader, criterion, optimizer_scratch, num_epochs)\n        auc_scratch = evaluate_model(model_scratch, test_loader)\n        print('auc_scratch is:', auc_scratch)\n        auc_scores_scratch.append(auc_scratch)\n\n    return auc_scores_scratch\n\n# Execute the trials\nauc_scratch = run_trials()\nprint(\"AUC Scores (Training from Scratch):\", auc_scratch)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**combination of CNN and transfomer**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\nfrom sklearn.metrics import roc_auc_score\n\nclass LowLevelFeatureExtractor(nn.Module):\n    def __init__(self, in_channels=3):\n        super(LowLevelFeatureExtractor, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n    def forward(self, x):\n        # Low-level features pipeline\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.pool(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.pool(x)\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = self.pool(x)\n        return x\n\nclass ConvNeXtHighLevelFeatures(nn.Module):\n    def __init__(self):\n        super(ConvNeXtHighLevelFeatures, self).__init__()\n        self.convnext = models.convnext_tiny(pretrained=True)\n        # Remove the classifier head\n        self.features = self.convnext.features\n\n    def forward(self, x):\n        # High-level features pipeline\n        x = self.features(x)\n        return x\n\nclass LungDiseaseClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(LungDiseaseClassifier, self).__init__()\n        # Initialize low-level and high-level feature extractors\n        self.low_level_extractor = LowLevelFeatureExtractor(in_channels=3)\n        self.high_level_extractor = ConvNeXtHighLevelFeatures()\n        \n        # Feature fusion and classification layers\n        self.fusion_conv = nn.Conv2d(128 + 768, 512, kernel_size=1)  # 128 from low-level, 768 from ConvNeXt\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(flattened_feature_size, 1024),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(1024, num_classes)\n        )\n\n    def forward(self, x):\n        # Step 1: Extract low-level features\n        low_level_features = self.low_level_extractor(x)  # Shape: [batch, 128, H/8, W/8]\n        \n        # Step 2: Extract high-level features\n        high_level_features = self.high_level_extractor(x)  # Shape: [batch, 768, H/32, W/32]\n        high_level_features = F.interpolate(high_level_features, size=low_level_features.shape[2:], mode='bilinear', align_corners=False)\n        \n        # Step 3: Fuse features\n        fused_features = torch.cat([low_level_features, high_level_features], dim=1)  # Concatenate along channel dimension\n        fused_features = self.fusion_conv(fused_features)  # Shape: [batch, 512, H/8, W/8]\n        \n        # Step 4: Classification\n        output = self.classifier(fused_features)\n        return output\n\n# ------------------------- Model Initialization -------------------------\n# Number of classes for the classification task\nnum_classes = len(classes)  # Replace `classes` with the number of disease labels\n\n# Initialize the model\nmodel = LungDiseaseClassifier(num_classes)\n\n# ------------------------- Loss and Optimizer -------------------------\ncriterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy for multi-label classification\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n# ------------------------- Training Loop -------------------------\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\n# Example training loop\n\n# Training loop with AUC computation\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    \n    # Training phase\n    for images, labels in train_loader:  # Ensure `train_loader` is defined\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)  # Forward pass\n        loss = criterion(outputs, labels)  # Compute loss\n        loss.backward()  # Backward pass\n        optimizer.step()  # Update weights\n        \n        total_loss += loss.item()\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_loss / len(train_loader):.4f}\")\n    \n    # Evaluation phase\n    model.eval()\n    all_targets = []\n    all_predictions = []\n    \n    with torch.no_grad():\n        for images, labels in test_loader:  # Ensure `test_loader` is defined\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)  # Get model predictions\n            \n            # Store predictions and true labels\n            all_predictions.append(torch.sigmoid(outputs).cpu().numpy())  # Convert logits to probabilities\n            all_targets.append(labels.cpu().numpy())\n    \n    # Flatten lists to compute AUC\n    all_targets = np.vstack(all_targets)  # Shape: [num_samples, num_classes]\n    all_predictions = np.vstack(all_predictions)  # Shape: [num_samples, num_classes]\n    \n    # Compute AUC for each class\n    aucs = []\n    for i in range(num_classes):  # Replace `num_classes` with the number of output classes\n        try:\n            auc = roc_auc_score(all_targets[:, i], all_predictions[:, i])\n        except ValueError:\n            auc = None  # Handle edge case where a class has only one label\n        aucs.append(auc)\n    \n    # Compute average AUC (excluding None values)\n    valid_aucs = [auc for auc in aucs if auc is not None]\n    mean_auc = sum(valid_aucs) / len(valid_aucs) if valid_aucs else 0\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}, Test AUC (per class): {aucs}\")\n    print(f\"Epoch {epoch+1}/{num_epochs}, Mean Test AUC: {mean_auc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**using Interimage**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom sklearn.metrics import roc_auc_score\nfrom timm import create_model\nfrom tqdm import tqdm\nimport torch.nn.functional as F\nfrom transformers import AutoModel, AutoConfig\n#from torchsummary import summary\nimport types\n\n\n# Define constants\nnum_epochs = 1\nlearning_rate = 0.0001\nbatch_size = 16\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Initialize model\ndef initialize_model(pretrained=True):\n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    my_config = AutoConfig.from_pretrained(\"OpenGVLab/internimage_t_1k_224\", torch_dtype=torch.float16, trust_remote_code=True)\n    model = AutoModel.from_config(my_config)\n    model.model.head = nn.Linear(in_features=768, out_features=len(classes))\n    #model.new_head = nn.Linear(768, len(classes))\n\n# Update forward pass manually\n    def forward_with_new_head(self, x):\n        #print(f\"Shape before all: {x.shape}\")\n        x = self.model(x)  # Original forward\n        if isinstance(x, tuple):\n            x = x[0]\n        #print(f\"Shape before new_head: {x.shape}\")\n        #x = self.new_head(x)  # New layer\n        #print(f\"Shape after new_head: {x.shape}\")\n        return x\n\n# Bind the new forward function to the model\n    \n    model.forward = types.MethodType(forward_with_new_head, model)\n    \n    #print(model)\n    #summary(model, input_size=(3,224,224))\n    return model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()  # For multi-label classification\n\ndef train_model(model, train_loader, criterion, optimizer, num_epochs):\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for images, labels in tqdm(train_loader):\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            #print('images.shape is:', images.shape)\n            outputs = model(images)\n            if isinstance(outputs, tuple):  # Some models may return multiple outputs\n                outputs = outputs[0]  # Extract the logits\n            #print('outputs1.shape is:', outputs.shape)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten to [batch_size, num_classes]\n            #print('outputs.shape is:', outputs.shape)\n            loss = criterion(outputs, labels.float())\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n        \n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n\n# Function to evaluate the model\ndef evaluate_model(model, test_loader):\n    model.eval()\n    all_labels = []\n    all_outputs = []\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images = images.to(device)\n            outputs = model(images)\n            outputs = outputs.view(outputs.size(0), -1)  # Flatten outputs\n            all_labels.append(labels.numpy())\n            all_outputs.append(torch.sigmoid(outputs).cpu().numpy())\n    \n    all_labels = np.vstack(all_labels)\n    all_outputs = np.vstack(all_outputs)\n    \n    return roc_auc_score(all_labels, all_outputs, average='macro')\n\n# Run independent trials for both training approaches\ndef run_trials(trials=1):\n    auc_scores_scratch = []\n    \n    for trial_num in range(trials):\n        # Training from scratch\n        model_scratch = initialize_model(pretrained=True)\n        optimizer_scratch = optim.Adam(model_scratch.parameters(), lr=learning_rate)\n        \n        train_model(model_scratch, train_loader, criterion, optimizer_scratch, num_epochs)\n        auc_scratch = evaluate_model(model_scratch, test_loader)\n        print('auc_scratch is:', auc_scratch)\n        auc_scores_scratch.append(auc_scratch)\n\n    return auc_scores_scratch\n\n# Execute the trials\nauc_scratch = run_trials()\nprint(\"AUC Scores (Training from Scratch):\", auc_scratch)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}